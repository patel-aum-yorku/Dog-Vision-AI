{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwoXMPt1qq7A"
      },
      "source": [
        "# üêï End-to-End Multi-Class Dog Breed Classification.\n",
        "\n",
        "This notebook builds an multi-class image classifier using TenserFlow 2.0 and TensorFlow Hub.\n",
        "\n",
        "## 1. Problem\n",
        "\n",
        "Indentifying the breed of a dog given an image of a dog.\n",
        "\n",
        "\"When I am sitting at a cafe and I see a cute dog, would love to know the breed of it.\"\n",
        "\n",
        "\n",
        "## 2. Data\n",
        "\n",
        "https://www.kaggle.com/c/dog-breed-identification/data\n",
        "\n",
        " The data we are using is from kaggle's dog breed indentification competitions.\n",
        "\n",
        "\n",
        "## 3. Evaluation\n",
        "\n",
        "The evalutions is a file with predictions probabilities for each dog breed of each test image.\n",
        "\n",
        "https://www.kaggle.com/c/dog-breed-identification/overview\n",
        "\n",
        "## 4. Features\n",
        "\n",
        "- We are dealing with images (unstructured data) so it's probably it is best to use deep learning/ transfer learning.\n",
        "\n",
        "- We have training set and a test set of images of dogs. Each image has a filename that is its unique id. The dataset comprises 120 breeds of dogs.\n",
        "\n",
        "- There are around 10,000+ images in the training set(these images have labels).\n",
        "- There are around 10,000+ images in the test set(these images have no labels).\n",
        "\n",
        "- File descriptions\n",
        "  - train.zip - the training set, you are provided the breed for these dogs\n",
        "  - test.zip - the test set, you must predict the probability of each breed for each image\n",
        "  - sample_submission.csv - a sample submission file in the correct format\n",
        "  - labels.csv - the breeds for the images in the train set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7OCqqP4K9bF"
      },
      "source": [
        "## Getting Workspace Ready\n",
        "\n",
        "- Import TensorFlow 2.x\n",
        "- Import TensorFlow Hub\n",
        "- Make sure we are using GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "try:\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
        "        b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
        "        c = tf.matmul(a, b)\n",
        "        print(\"Matrix multiplication on GPU successful:\\n\", c.numpy())\n",
        "except RuntimeError as e:\n",
        "    print(f\"Error running on GPU: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMPpYAmptJPK",
        "outputId": "6a1e0780-2b6f-4f07-e76d-e6cb2b511dc4"
      },
      "outputs": [],
      "source": [
        "#Import neccesary tools\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5LhRZaqq5ai"
      },
      "source": [
        "## Getting our data ready (turning it into Tensors)\n",
        "\n",
        "With all machine learning models, our data should be in numerical format. So, that's what we'll be doing first. Turning our images into Tensors (numerical representation more like numpy arrays with multiple dimensions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE4g2tgsrjv5",
        "outputId": "9ef54f83-6c3c-4251-853b-0685cdd7f088"
      },
      "outputs": [],
      "source": [
        "# checkout labels of our data\n",
        "import pandas as pd\n",
        "labels_csv = pd.read_csv(\"/content/drive/MyDrive/Dog Vision/labels.csv\")\n",
        "print(labels_csv.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nqJ3Tw2Tssz0",
        "outputId": "09c93066-2754-4b77-b24e-fdd68f26a3a4"
      },
      "outputs": [],
      "source": [
        "labels_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "g0UOhaq1tAMw",
        "outputId": "eca59d70-579e-4874-bafc-afd42d61e439"
      },
      "outputs": [],
      "source": [
        "# how many images are there of each breed\n",
        "labels_csv[\"breed\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "CJgfo0ZxtRm0",
        "outputId": "1e48e3b0-c1bb-4783-c97e-9549a24400d8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "breed_counts = labels_csv[\"breed\"].value_counts()\n",
        "\n",
        "# Create the bar plot\n",
        "plt.figure(figsize=(20, 10))  # Adjust figure size as needed\n",
        "breed_counts.plot(kind='bar')\n",
        "plt.title('Number of Images per Dog Breed')\n",
        "plt.xlabel('Dog Breed')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.xticks(rotation=90)  # Rotate x-axis labels for readability\n",
        "plt.tight_layout()  # Adjust layout to prevent labels from overlapping\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCn9NcWZtms1",
        "outputId": "6ec7201d-6b61-442c-dd87-e65ecf3ab7ba"
      },
      "outputs": [],
      "source": [
        "labels_csv[\"breed\"].value_counts().median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "kuyQ--e2v5rK",
        "outputId": "534ccb00-6061-4216-d506-87cfa2234e38"
      },
      "outputs": [],
      "source": [
        "# Viewing the image\n",
        "from IPython.display import Image\n",
        "Image(\"/content/drive/MyDrive/Dog Vision/train/0021f9ceb3235effd7fcde7f7538ed62.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76fNbskHwqzx"
      },
      "source": [
        "### Getting images and there labels\n",
        "\n",
        "Lets get list of all of our image file pathnames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTtQZTIZw__v"
      },
      "outputs": [],
      "source": [
        "labels_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OQ1x5y7yw0PJ"
      },
      "outputs": [],
      "source": [
        "# Create pathnames from image ID's\n",
        "filenames = [\"/content/drive/MyDrive/Dog Vision/train/\"+fname for fname in labels_csv[\"id\"]+\".jpg\"]\n",
        "filenames[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6870lkjyG9a"
      },
      "outputs": [],
      "source": [
        "Image(filenames[11])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3-M1WKwyhup"
      },
      "outputs": [],
      "source": [
        "# check whether number of filename matches number of actual image files\n",
        "import os\n",
        "if len(os.listdir(\"/content/drive/MyDrive/Dog Vision/train\")) == len(filenames):\n",
        "  print(\"Filenames match actual amount of files\")\n",
        "else:\n",
        "  print(\"Filenames do not match actual amount of files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5WIcJLnz1Nv"
      },
      "source": [
        "Since we'have now got our training image filepaths in a list. lets prepare our labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYrigH-zz_Vc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "labels = labels_csv[\"breed\"]#.to_numpy() does same thing as below\n",
        "labels = np.array(labels)\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oN2CVwwl0H7w"
      },
      "outputs": [],
      "source": [
        "len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ActCfuDV0pvp"
      },
      "outputs": [],
      "source": [
        "# Check if number of labels matches the number of filenames to see if there are missing data\n",
        "if len(labels) == len(filenames):\n",
        "  print(\"Number of labels matches number of filenames\")\n",
        "else:\n",
        "  print(\"Number of labels does not match number of filenames\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52gq4m_u1Gv8"
      },
      "outputs": [],
      "source": [
        "# Find the unique label values\n",
        "unique_breeds = np.unique(labels)\n",
        "len(unique_breeds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irgjC8so1w48"
      },
      "outputs": [],
      "source": [
        "# turn a single label into an array of booleans\n",
        "print(labels[0])\n",
        "labels[0] == unique_breeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1r2vcdG2Hmq"
      },
      "outputs": [],
      "source": [
        "# Turn every single labels into boolean array\n",
        "boolean_labels = [label == unique_breeds for label in labels]\n",
        "boolean_labels[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_mP47q72YNz"
      },
      "outputs": [],
      "source": [
        "len(boolean_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvuBCBAu4SvY"
      },
      "source": [
        "### Creating our own validation set\n",
        "\n",
        "Our data set does not have a validation set so, we will need to create one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWV1UT1B4ioM"
      },
      "outputs": [],
      "source": [
        "# Set up X and y variables\n",
        "X = filenames # this is our training and validation input the images\n",
        "y = boolean_labels # this is our target labels, they are boolean arrays\n",
        "# each array has a true value corresponding to the label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2fL7G0V5ejd"
      },
      "source": [
        "We are going to start off experinmenting with ~1000 images and then increase as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c76h-KR_5QcV"
      },
      "outputs": [],
      "source": [
        "# Set number of images to use for experimenting\n",
        "NUM_IMAGES = 1000 # @param {\"type\":\"slider\",\"min\":1000,\"max\":10222,\"step\":100}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-7GKxD26Voa"
      },
      "outputs": [],
      "source": [
        "# Lets split our data into train and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# split them into training and validation of total size NUM_IMAGES\n",
        "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES], y[:NUM_IMAGES],\n",
        "                                                  test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quklCAb08wp7"
      },
      "outputs": [],
      "source": [
        "len(X_train), len(y_train), len(X_val), len(y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5viC5H19VOD"
      },
      "source": [
        "## Preprocessing Images (turning images into tensors)\n",
        "\n",
        "To preprocess our images into Tensors we are going to write a fucntion which does a few things:\n",
        "\n",
        "1. Take image filepath as input.\n",
        "2. Use TensorFlow to read the file and save it to a variable, `image`.\n",
        "3. Turn our `image` (a jpg) into Tensors.\n",
        "4. Normalize our image (convert color channel values from 0-255 to 0-1)\n",
        "5. Resize the `image` to be a shape of (224,224).\n",
        "The reason for specific size depends on which model you choose to train. Certain models have size requirements.\n",
        "6. Return the modified `image`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjhL4kIUxOot"
      },
      "outputs": [],
      "source": [
        "# convert image to NumPy array\n",
        "# .shape gives this info (height, width, color chanels)\n",
        "# color chanels 3 means it is RGB\n",
        "from matplotlib.pyplot import imread\n",
        "image = imread(filenames[42])\n",
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qIdEVEwyKzf"
      },
      "outputs": [],
      "source": [
        "image.max(), image.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWYbs93tytY6"
      },
      "outputs": [],
      "source": [
        "image[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrtL-T_Zyawe"
      },
      "outputs": [],
      "source": [
        "# turn image into tensor\n",
        "tf.constant(image)[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beXfhjrNzOvP"
      },
      "source": [
        "#### Now we have seen what image looks like as tensor, so lets build a function to preprocess them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFHqLT51zcKg"
      },
      "outputs": [],
      "source": [
        "# Define image size which is (224, 224)\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# Create a funtion for preproccessing images\n",
        "def process_image(image_path):\n",
        "  \"\"\"\n",
        "  1. Takes an image file path and turns it into a Tensor.\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  2. Use TensorFlow to read the file and save it to a variable, image.\n",
        "  \"\"\"\n",
        "  # Read in an Image file\n",
        "  image = tf.io.read_file(image_path)\n",
        "\n",
        "  \"\"\"\n",
        "  3. Turn the jpg image into numerical tensor with 3 colour chanels (Red, Green, Blue)\n",
        "  \"\"\"\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "  \"\"\"\n",
        "  4. covert the color channel values from 0-255 to 0-1 values, part of normalizatiom\n",
        "  \"\"\"\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "  \"\"\"\n",
        "  5. Resize the image to be a shape of (224,224).\n",
        "  \"\"\"\n",
        "  image = tf.image.resize(image, size=[IMG_SIZE,IMG_SIZE])\n",
        "\n",
        "  \"\"\"\n",
        "  6. Return the modified image\n",
        "  \"\"\"\n",
        "  return image\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky5GXC9DP-DB"
      },
      "source": [
        "## Turning our data into batches\n",
        "\n",
        "<strong> Our approach will be to use mini batch training where our batches will be of 32 images.</strong>\n",
        "\n",
        "Reason:\n",
        "- Let's say we have 10000+ images to process in one go, it will not fit on memory (Even with GPUs).\n",
        "- Slows down our training process.\n",
        "- It is in-efficient.\n",
        "\n",
        "So, thats why we will train in batches of 32 images at time. (you can manually adjust the batch size)\n",
        "\n",
        "In order to use TensorFlow effectively, we need our data to be in form of Tensor tuples which looks like this:\n",
        "`(image,label)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hby0WjltRoSn"
      },
      "outputs": [],
      "source": [
        "# Create simple function to return a tuple -> (image, label)\n",
        "def get_image_label(image_path, label):\n",
        "  '''\n",
        "  Takes an image file path name and the associated label,\n",
        "  processes the image and returns a tuple of (image, label).\n",
        "  '''\n",
        "  image = process_image(image_path)\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf0fgVChSV_W"
      },
      "outputs": [],
      "source": [
        "(process_image(X[42], y[42]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
